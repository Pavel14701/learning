import asyncio
from typing import Any, Dict, List

import keras._tf_keras.keras as keras  # type: ignore
import numpy as np
import tensorflow as tf
from keras._tf_keras.keras.layers import (  # type: ignore
    BatchNormalization,
    Dense,
    Dropout,
)
from keras._tf_keras.keras.optimizers import Adam  # type: ignore
from sklearn.preprocessing import StandardScaler  # type: ignore 


class ApproximationModel:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏–∏"""

    def __init__(self, learning_rate: float = 0.00001) -> None:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏"""
        self.model: keras.Sequential = self._build_model()
        self.learning_rate: float = learning_rate

        # üîπ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö GPU –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
        self._set_gpu_device()

    def _set_gpu_device(self) -> None:
        """–ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU"""
        gpu_devices = tf.config.list_physical_devices('GPU')
        if gpu_devices:
            tf.config.set_visible_devices(gpu_devices[0], 'GPU')
            print("üöÄ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è GPU:", gpu_devices[0])
        else:
            print("‚ö† GPU –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU")

    def _build_model(self) -> keras.Sequential:
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏–∏ kx + a + b*sin(cx + d)"""
        model = keras.Sequential([
            Dense(128, activation='relu', input_shape=(1,)),
            BatchNormalization(),
            Dropout(0.2),
            Dense(128, activation='relu'),
            BatchNormalization(),
            Dropout(0.2),
            Dense(5)
        ])
        return model

    @staticmethod
    def custom_loss(y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:
        """–ö–∞—Å—Ç–æ–º–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å –¥–ª—è –º–æ–¥–µ–ª–∏ –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏–∏"""
        k, a, b, c, d = tf.split(y_pred, num_or_size_splits=5, axis=1)
        x, y_true_values = tf.split(y_true, num_or_size_splits=2, axis=1)
        y_pred_values = k * x + a + b * tf.sin(c * x + d)
        mse_loss = keras.losses.Huber()(y_true_values, y_pred_values)
        reg_loss = 0.001 * tf.reduce_mean(
            tf.square(k) + tf.square(a) + tf.square(b) + tf.square(c) + tf.square(d)
        )
        return mse_loss + reg_loss

    async def train_segment_async(
        self, 
        seg: Dict[str, np.ndarray]
    ) -> keras.Sequential:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –æ–¥–Ω–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞"""
        time_seg: np.ndarray = seg['time'].reshape(-1, 1)
        vel_seg: np.ndarray = seg['velocity'].reshape(-1, 1)
        scaler_X: StandardScaler = StandardScaler()
        scaler_y: StandardScaler = StandardScaler()
        X_scaled: np.ndarray = scaler_X.fit_transform(time_seg)
        y_scaled: np.ndarray = scaler_y.fit_transform(vel_seg)
        X_scaled_tf: tf.Tensor = tf.convert_to_tensor(X_scaled, dtype=tf.float32)
        y_true_for_loss_tf: tf.Tensor = tf.convert_to_tensor(
            np.column_stack([X_scaled, y_scaled]), 
            dtype=tf.float32
        )

        optimizer = Adam(learning_rate=self.learning_rate)
        self.model.compile(optimizer=optimizer, loss=self.custom_loss)

        # üîπ –£–¥–∞–ª—ë–Ω `tf.device('/GPU:0')`, —Ç–µ–ø–µ—Ä—å GPU –≤—ã–±–∏—Ä–∞–µ—Ç—Å—è –∑–∞—Ä–∞–Ω–µ–µ
        await asyncio.to_thread(
            self.model.fit, 
            X_scaled_tf, 
            y_true_for_loss_tf, 
            epochs=300, 
            verbose=1
        )
        return self.model

    async def train_parallel_async(
        self, 
        segments: List[Dict[str, Any]]
    ) -> List[keras.Sequential]:
        """–ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ"""
        tasks = [self.train_segment_async(seg) for seg in segments]
        models = await asyncio.gather(*tasks)
        return models
